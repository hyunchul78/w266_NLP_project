# NLP_sentence_gen
1. The repository contains notebooks for hyperparameter tuning experiments and Final_code folder that contains baseline model and model that generates the lowest training and validation loss. 

    1.1 File name explanation 
        i) i.e. 300_e1_d1_ls32_itm96.ipynb --> GloVe dimension 300, encoder LSTM 1 layer, decoder LSTM 1 layer, latent space 32, LSTM parameter 96       
        ii) base model: base model used in paper. 
        iii) best model: model that generates least training and validation loss based on the hyperparameter tuning experiment
        
   
2. Google drive link for Pre-trained Word embedding weights, Quora datasets (train.csv) and weights generated by jupyter notebooks for hyperparameter tuning
    
    https://drive.google.com/drive/folders/1UN3-kqim2eyRGaGBbhOGDzdJuWZvfUAg?usp=sharing
   


 