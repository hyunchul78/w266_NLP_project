{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed, Layer, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from scipy import spatial\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories and text loading\n",
    "Initially we will set the main directories and some variables regarding the characteristics of our texts.\n",
    "We set the maximum sequence length to 15, the maximun number of words in our vocabulary to 12000 and we will use 50-dimensional embeddings. Finally we load our texts from a csv. The text file is the train file of the Quora Kaggle challenge containing around 808000 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV (Comma Separated Values)\n",
    "Format for spreadsheets and databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 808580 texts in train.csv\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '../'\n",
    "TRAIN_DATA_FILE = BASE_DIR + 'train.csv'\n",
    "\n",
    "texts = [] \n",
    "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        texts.append(values[3])\n",
    "        texts.append(values[4])\n",
    "print('Found %s texts in train.csv' % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "To preprocess the text we will use the tokenizer and the text_to_sequences function from Keras\n",
    "\n",
    "- `Tokenizer(num_words)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95596 unique tokens\n",
      "Shape of data tensor: (808580, 15)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 15\n",
    "MAX_NB_WORDS = 12000\n",
    "\n",
    "tokenizer = Tokenizer(MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# {key=word : value:index}\n",
    "word_index = tokenizer.word_index #the dict values start from 1 so this is fine with zeropadding\n",
    "# {key=index : value:word}\n",
    "index2word = {v: k for k, v in word_index.items()}\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data_1 = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data_1.shape)\n",
    "\n",
    "NB_WORDS = (min(tokenizer.num_words, len(word_index)) + 1 ) #+1 for zero padding\n",
    "data_1_val = data_1[801000:807000] #select 6000 sentences as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "[2, 3, 1, 1222, 57, 1222, 2581, 7, 576, 8, 763, 383, 8, 35]\n",
      "What does it mean when a guy says I like you?\n",
      "[2, 21, 19, 101, 37, 6, 287, 716, 5, 39, 15]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(sequences[0])\n",
    "\n",
    "print(texts[1000])\n",
    "print(sequences[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence generator\n",
    "In order to reduce the memory requirements we will gradually read our sentences from the csv through Pandas as we feed them to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_generator(TRAIN_DATA_FILE, chunksize):\n",
    "    reader = pd.read_csv(TRAIN_DATA_FILE, chunksize=chunksize, iterator=True)\n",
    "    for df in reader:\n",
    "        val3 = df.iloc[:,3:4].values.tolist()\n",
    "        val4 = df.iloc[:,4:5].values.tolist()\n",
    "        flat3 = [item for sublist in val3 for item in sublist]\n",
    "        flat4 = [str(item) for sublist in val4 for item in sublist]\n",
    "        texts = [] \n",
    "        # 'Append' add x, but extend add x's elements\n",
    "        texts.extend(flat3[:]) # Column Question1\n",
    "        texts.extend(flat4[:]) # Column Question2\n",
    "        sequences = tokenizer.texts_to_sequences(texts)\n",
    "        data_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "        yield (data_train, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "We will use pretrained Glove word embeddings as embeddings for our network. We create a matrix with one embedding for every word in our vocabulary and then we will pass this matrix as weights to the keras embedding layer of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "GLOVE_EMBEDDING = BASE_DIR + 'GloVe/glove.6B.50d.txt'\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(GLOVE_EMBEDDING, encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "glove_embedding_matrix = np.zeros((NB_WORDS, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i < NB_WORDS:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be the word embedding of 'unk'.\n",
    "            glove_embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            glove_embedding_matrix[i] = embeddings_index.get('unk')\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(glove_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE model\n",
    "Our model is based on a seq2seq architecture with a bidirectional LSTM encoder and an LSTM decoder and ELU activations.\n",
    "We feed the latent representation at every timestep as input to the decoder through \"RepeatVector(max_len)\".\n",
    "To avoid the one-hot representation of labels we use the \"tf.contrib.seq2seq.sequence_loss\" that requires as labels only the word indexes (the same that go in input to the embedding matrix) and calculates internally the final softmax (so the model ends with a dense layer with linear activation). Optionally the \"sequence_loss\" allows to use the sampled softmax which helps when dealing with large vocabularies (for example with a 50k words vocabulary) but in this I didn't use it.\n",
    "Moreover, due to the pandas iterator that reads the csv both the train size and validation size must be divisible by the batch_size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Linear Unit or its widely known name ELU is a function that tend to converge cost to zero faster and produce more accurate results. Different to other activation functions, ELU has a extra alpha constant which should be positive number.\n",
    "\n",
    "ELU is very similiar to RELU except negative inputs. They are both in identity function form for non-negative inputs. On the other hand, ELU becomes smooth slowly until its output equal to -Î± whereas RELU sharply smoothes.\n",
    "\n",
    "https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ines/anaconda3/envs/tensorflow_gpu_1_13/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(?, 15) (100, 15, 12001)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 15, 50)       600050      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 192)          112896      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 192)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 96)           18528       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu (ELU)                       (None, 96)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 96)           0           elu[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           3104        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           3104        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (100, 32)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (100, 15, 32)        0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (100, 15, 96)        49536       repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (100, 15, 12001)     1164097     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer (Custo (None, 15)           0           input_1[0][0]                    \n",
      "                                                                 time_distributed[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,951,315\n",
      "Trainable params: 1,351,265\n",
      "Non-trainable params: 600,050\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "max_len = MAX_SEQUENCE_LENGTH\n",
    "emb_dim = EMBEDDING_DIM\n",
    "latent_dim = 32\n",
    "intermediate_dim = 96\n",
    "epsilon_std = 1.0\n",
    "act = ELU()\n",
    "\n",
    "x = Input(batch_shape=(None, max_len))\n",
    "x_embed = Embedding(NB_WORDS, emb_dim, weights=[glove_embedding_matrix],\n",
    "                            input_length=max_len, trainable=False)(x)\n",
    "h = Bidirectional(LSTM(intermediate_dim, return_sequences=False, recurrent_dropout=0.2), merge_mode='concat')(x_embed)\n",
    "h = Dropout(0.2)(h)\n",
    "h = Dense(intermediate_dim, activation='linear')(h)\n",
    "h = act(h)\n",
    "h = Dropout(0.2)(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "repeated_context = RepeatVector(max_len)\n",
    "decoder_h = LSTM(intermediate_dim, return_sequences=True, recurrent_dropout=0.2)\n",
    "decoder_mean = TimeDistributed(Dense(NB_WORDS, activation='linear'))#softmax is applied in the seq2seqloss by tf\n",
    "h_decoded = decoder_h(repeated_context(z))\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "# placeholder loss\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return K.zeros_like(y_pred)\n",
    "\n",
    "# Custom VAE loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "        self.target_weights = tf.constant(np.ones((batch_size, max_len)), tf.float32)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        #xent_loss = K.sum(metrics.categorical_crossentropy(x, x_decoded_mean), axis=-1)\n",
    "        labels = tf.cast(x, tf.int32)\n",
    "        xent_loss = K.sum(tf.contrib.seq2seq.sequence_loss(x_decoded_mean, labels, \n",
    "                                                     weights=self.target_weights,\n",
    "                                                     average_across_timesteps=False,\n",
    "                                                     average_across_batch=False), axis=-1)\n",
    "                                                     #softmax_loss_function=softmax_loss_f), axis=-1)#, uncomment for sampled doftmax\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        print(x.shape, x_decoded_mean.shape)\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # we don't use this output, but it has to have the correct shape:\n",
    "        return K.ones_like(x)\n",
    "\n",
    "loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "vae = Model(x, [loss_layer])\n",
    "opt = Adam(lr=0.01)\n",
    "vae.compile(optimizer='adam', loss=[zero_loss])\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "We train our model for 100 epochs through keras \".fit_generator\". The number of steps per epoch is equal to the number of sentences that we have in the train set (800000) divided by the batch size; the additional /2 is due to the fact that our csv has two sentnces per line so in the end we have to read with our generator only 400000 lines per epoch.\n",
    "For validation data we pass the same array twice since input and labels of this model are the same. \n",
    "If we didn't use the \"tf.contrib.seq2seq.sequence_loss\" (or another similar function) we would have had to pass as labels the sequence of word one-hot encodings with dimension (batch_size, seq_len, vocab_size) consuming a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callback = TensorBoard(log_dir)\n",
    "callback.set_model([vae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(callback, names, logs, batch_no):\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = logs[0].history['loss'][0]\n",
    "    summary_value.tag = names[0]\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = logs[0].history['val_loss'][0]\n",
    "    summary_value.tag = names[1]\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------epoch:  0 --------\n",
      "6000/6000 [==============================] - 1s 206us/sample - loss: 65.5511\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 39ms/step - loss: 73.4179 - val_loss: 65.5511\n",
      "-------epoch:  1 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 64.2915\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 65.0546 - val_loss: 64.2915\n",
      "-------epoch:  2 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 63.5929\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 64.1313 - val_loss: 63.5929\n",
      "-------epoch:  3 --------\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 63.0016\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 63.5557 - val_loss: 63.0016\n",
      "-------epoch:  4 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 62.7652\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 63.1448 - val_loss: 62.7652\n",
      "-------epoch:  5 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 62.4761\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 62.8902 - val_loss: 62.4761\n",
      "-------epoch:  6 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 62.4520\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 62.7250 - val_loss: 62.4520\n",
      "-------epoch:  7 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 62.2218\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 62.5849 - val_loss: 62.2218\n",
      "-------epoch:  8 --------\n",
      "6000/6000 [==============================] - 1s 166us/sample - loss: 62.0932\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 62.4726 - val_loss: 62.0932\n",
      "-------epoch:  9 --------\n",
      "6000/6000 [==============================] - 1s 168us/sample - loss: 61.9862\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 38ms/step - loss: 62.3645 - val_loss: 61.9862\n",
      "-------epoch:  10 --------\n",
      "6000/6000 [==============================] - 1s 167us/sample - loss: 61.9325\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 62.2801 - val_loss: 61.9325\n",
      "-------epoch:  11 --------\n",
      "6000/6000 [==============================] - 1s 167us/sample - loss: 61.8398\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 62.1928 - val_loss: 61.8398\n",
      "-------epoch:  12 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 61.9636\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 62.1173 - val_loss: 61.9636\n",
      "-------epoch:  13 --------\n",
      "6000/6000 [==============================] - 1s 166us/sample - loss: 61.8252\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 150s 37ms/step - loss: 62.0387 - val_loss: 61.8252\n",
      "-------epoch:  14 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 61.6090\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 61.9437 - val_loss: 61.6090\n",
      "-------epoch:  15 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 61.5786\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 61.8606 - val_loss: 61.5786\n",
      "-------epoch:  16 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 61.4029\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 61.7829 - val_loss: 61.4029\n",
      "-------epoch:  17 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 61.3911\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 150s 37ms/step - loss: 61.7232 - val_loss: 61.3911\n",
      "-------epoch:  18 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 61.3678\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 150s 37ms/step - loss: 61.6738 - val_loss: 61.3678\n",
      "-------epoch:  19 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 61.2968\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 61.6242 - val_loss: 61.2968\n",
      "-------epoch:  20 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 61.3799\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 39ms/step - loss: 61.5649 - val_loss: 61.3799\n",
      "-------epoch:  21 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 61.2728\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 61.5198 - val_loss: 61.2728\n",
      "-------epoch:  22 --------\n",
      "6000/6000 [==============================] - 1s 168us/sample - loss: 61.2010\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 61.4614 - val_loss: 61.2010\n",
      "-------epoch:  23 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 61.2194\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 61.3945 - val_loss: 61.2194\n",
      "-------epoch:  24 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 61.1409\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 61.3547 - val_loss: 61.1409\n",
      "-------epoch:  25 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 61.2323\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 61.3052 - val_loss: 61.2323\n",
      "-------epoch:  26 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 61.0925\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 61.2684 - val_loss: 61.0925\n",
      "-------epoch:  27 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 61.0858\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 61.2317 - val_loss: 61.0858\n",
      "-------epoch:  28 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 61.0919\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 61.2015 - val_loss: 61.0919\n",
      "-------epoch:  29 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 61.0022\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 61.1610 - val_loss: 61.0022\n",
      "-------epoch:  30 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 61.0538\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 149s 37ms/step - loss: 61.1209 - val_loss: 61.0538\n",
      "-------epoch:  31 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 60.9984\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 61.0831 - val_loss: 60.9984\n",
      "-------epoch:  32 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 61.0192\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 155s 39ms/step - loss: 61.0622 - val_loss: 61.0192\n",
      "-------epoch:  33 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 60.9616\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 61.0290 - val_loss: 60.9616\n",
      "-------epoch:  34 --------\n",
      "6000/6000 [==============================] - 1s 171us/sample - loss: 61.0011\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 61.0032 - val_loss: 61.0011\n",
      "-------epoch:  35 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 60.9668\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 60.9782 - val_loss: 60.9668\n",
      "-------epoch:  36 --------\n",
      "6000/6000 [==============================] - 1s 172us/sample - loss: 60.9412\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 60.9507 - val_loss: 60.9412\n",
      "-------epoch:  37 --------\n",
      "6000/6000 [==============================] - 1s 168us/sample - loss: 60.9007\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 60.9252 - val_loss: 60.9007\n",
      "-------epoch:  38 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.8938\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.9009 - val_loss: 60.8938\n",
      "-------epoch:  39 --------\n",
      "6000/6000 [==============================] - 1s 198us/sample - loss: 60.8754\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 39ms/step - loss: 60.8694 - val_loss: 60.8754\n",
      "-------epoch:  40 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 60.8649\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.8451 - val_loss: 60.8649\n",
      "-------epoch:  41 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 60.8304\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 38ms/step - loss: 60.8167 - val_loss: 60.8304\n",
      "-------epoch:  42 --------\n",
      "6000/6000 [==============================] - 1s 166us/sample - loss: 60.8606\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.7902 - val_loss: 60.8606\n",
      "-------epoch:  43 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.8322\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.7633 - val_loss: 60.8322\n",
      "-------epoch:  44 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 60.8210\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.7455 - val_loss: 60.8210\n",
      "-------epoch:  45 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.8611\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 38ms/step - loss: 60.7181 - val_loss: 60.8611\n",
      "-------epoch:  46 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.7607\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 60.6936 - val_loss: 60.7607\n",
      "-------epoch:  47 --------\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 60.7781\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.6514 - val_loss: 60.7781\n",
      "-------epoch:  48 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.8235\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 60.6396 - val_loss: 60.8235\n",
      "-------epoch:  49 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.6991\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 60.6127 - val_loss: 60.6991\n",
      "-------epoch:  50 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 60.6971\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.5913 - val_loss: 60.6971\n",
      "-------epoch:  51 --------\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 60.6656\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.5666 - val_loss: 60.6656\n",
      "-------epoch:  52 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 60.6651\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 60.5372 - val_loss: 60.6651\n",
      "-------epoch:  53 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 60.6935\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.5142 - val_loss: 60.6935\n",
      "-------epoch:  54 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.6008\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.4934 - val_loss: 60.6008\n",
      "-------epoch:  55 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 60.6328\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.4657 - val_loss: 60.6328\n",
      "-------epoch:  56 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 60.5750\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.4466 - val_loss: 60.5750\n",
      "-------epoch:  57 --------\n",
      "6000/6000 [==============================] - 1s 173us/sample - loss: 60.5281\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.4212 - val_loss: 60.5281\n",
      "-------epoch:  58 --------\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 60.5421\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 159s 40ms/step - loss: 60.3968 - val_loss: 60.5421\n",
      "-------epoch:  59 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 60.4952\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 159s 40ms/step - loss: 60.3779 - val_loss: 60.4952\n",
      "-------epoch:  60 --------\n",
      "6000/6000 [==============================] - 1s 172us/sample - loss: 60.5540\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 39ms/step - loss: 60.3588 - val_loss: 60.5540\n",
      "-------epoch:  61 --------\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 60.5395\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 39ms/step - loss: 60.3426 - val_loss: 60.5395\n",
      "-------epoch:  62 --------\n",
      "6000/6000 [==============================] - 1s 172us/sample - loss: 60.5044\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 39ms/step - loss: 60.3188 - val_loss: 60.5044\n",
      "-------epoch:  63 --------\n",
      "6000/6000 [==============================] - 1s 178us/sample - loss: 60.4963\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 159s 40ms/step - loss: 60.2978 - val_loss: 60.4963\n",
      "-------epoch:  64 --------\n",
      "6000/6000 [==============================] - 1s 174us/sample - loss: 60.4874\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 162s 40ms/step - loss: 60.2882 - val_loss: 60.4874\n",
      "-------epoch:  65 --------\n",
      "6000/6000 [==============================] - 1s 188us/sample - loss: 60.4016\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 164s 41ms/step - loss: 60.2578 - val_loss: 60.4016\n",
      "-------epoch:  66 --------\n",
      "6000/6000 [==============================] - 1s 176us/sample - loss: 60.3964\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 60.2377 - val_loss: 60.3964\n",
      "-------epoch:  67 --------\n",
      "6000/6000 [==============================] - 1s 168us/sample - loss: 60.3364\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.2276 - val_loss: 60.3364\n",
      "-------epoch:  68 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 60.3091\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.2022 - val_loss: 60.3091\n",
      "-------epoch:  69 --------\n",
      "6000/6000 [==============================] - 1s 166us/sample - loss: 60.2920\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 60.1889 - val_loss: 60.2920\n",
      "-------epoch:  70 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 60.3616\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 60.1730 - val_loss: 60.3616\n",
      "-------epoch:  71 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 60.2664\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.1473 - val_loss: 60.2664\n",
      "-------epoch:  72 --------\n",
      "6000/6000 [==============================] - 1s 166us/sample - loss: 60.3435\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.1411 - val_loss: 60.3435\n",
      "-------epoch:  73 --------\n",
      "6000/6000 [==============================] - 1s 200us/sample - loss: 60.3156\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 39ms/step - loss: 60.1254 - val_loss: 60.3156\n",
      "-------epoch:  74 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.2341\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.1155 - val_loss: 60.2341\n",
      "-------epoch:  75 --------\n",
      "6000/6000 [==============================] - 1s 160us/sample - loss: 60.3062\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.0923 - val_loss: 60.3062\n",
      "-------epoch:  76 --------\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 60.2284\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 60.0886 - val_loss: 60.2284\n",
      "-------epoch:  77 --------\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 60.2348\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 60.0789 - val_loss: 60.2348\n",
      "-------epoch:  78 --------\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 60.2602\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 60.0614 - val_loss: 60.2602\n",
      "-------epoch:  79 --------\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 60.6494\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 151s 38ms/step - loss: 60.0488 - val_loss: 60.6494\n",
      "-------epoch:  80 --------\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 60.1625\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 60.0355 - val_loss: 60.1625\n",
      "-------epoch:  81 --------\n",
      "6000/6000 [==============================] - 1s 172us/sample - loss: 60.2585\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 60.0200 - val_loss: 60.2585\n",
      "-------epoch:  82 --------\n",
      "6000/6000 [==============================] - 1s 174us/sample - loss: 60.2606\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 60.0084 - val_loss: 60.2606\n",
      "-------epoch:  83 --------\n",
      "6000/6000 [==============================] - 1s 171us/sample - loss: 60.1693\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 59.9920 - val_loss: 60.1693\n",
      "-------epoch:  84 --------\n",
      "6000/6000 [==============================] - 1s 173us/sample - loss: 60.1459\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 40ms/step - loss: 59.9793 - val_loss: 60.1459\n",
      "-------epoch:  85 --------\n",
      "6000/6000 [==============================] - 1s 173us/sample - loss: 60.2000\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 158s 40ms/step - loss: 59.9677 - val_loss: 60.2000\n",
      "-------epoch:  86 --------\n",
      "6000/6000 [==============================] - 1s 172us/sample - loss: 60.1360\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 59.9682 - val_loss: 60.1360\n",
      "-------epoch:  87 --------\n",
      "6000/6000 [==============================] - 1s 172us/sample - loss: 60.2150\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 59.9451 - val_loss: 60.2150\n",
      "-------epoch:  88 --------\n",
      "6000/6000 [==============================] - 1s 171us/sample - loss: 60.1870\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 160s 40ms/step - loss: 59.9427 - val_loss: 60.1870\n",
      "-------epoch:  89 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 60.1634\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 156s 39ms/step - loss: 59.9176 - val_loss: 60.1634\n",
      "-------epoch:  90 --------\n",
      "6000/6000 [==============================] - 1s 168us/sample - loss: 60.1964\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 59.9172 - val_loss: 60.1964\n",
      "-------epoch:  91 --------\n",
      "6000/6000 [==============================] - 1s 167us/sample - loss: 60.1139\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 39ms/step - loss: 59.9050 - val_loss: 60.1139\n",
      "-------epoch:  92 --------\n",
      "6000/6000 [==============================] - 1s 173us/sample - loss: 60.2276\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 59.8900 - val_loss: 60.2276\n",
      "-------epoch:  93 --------\n",
      "6000/6000 [==============================] - 1s 169us/sample - loss: 60.1980\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 59.8791 - val_loss: 60.1980\n",
      "-------epoch:  94 --------\n",
      "6000/6000 [==============================] - 1s 170us/sample - loss: 60.1122\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 154s 39ms/step - loss: 59.8655 - val_loss: 60.1122\n",
      "-------epoch:  95 --------\n",
      "6000/6000 [==============================] - 1s 167us/sample - loss: 60.1169\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 59.8574 - val_loss: 60.1169\n",
      "-------epoch:  96 --------\n",
      "6000/6000 [==============================] - 1s 173us/sample - loss: 60.2050\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 155s 39ms/step - loss: 59.8479 - val_loss: 60.2050\n",
      "-------epoch:  97 --------\n",
      "6000/6000 [==============================] - 1s 171us/sample - loss: 60.1864\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 156s 39ms/step - loss: 59.8288 - val_loss: 60.1864\n",
      "-------epoch:  98 --------\n",
      "6000/6000 [==============================] - 1s 167us/sample - loss: 60.1439\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 59.8205 - val_loss: 60.1439\n",
      "-------epoch:  99 --------\n",
      "6000/6000 [==============================] - 1s 165us/sample - loss: 60.0932\n",
      "\n",
      "Epoch 00001: saving model to models/vae_seq2seq.h5\n",
      "4000/4000 [==============================] - 152s 38ms/step - loss: 59.8162 - val_loss: 60.0932\n"
     ]
    }
   ],
   "source": [
    "def create_model_checkpoint(dir, model_name):\n",
    "    filepath = dir + '/' + model_name + \".h5\" #-{epoch:02d}-{decoded_mean:.2f}\n",
    "    directory = os.path.dirname(filepath)\n",
    "    try:\n",
    "        os.stat(directory)\n",
    "    except:\n",
    "        os.mkdir(directory)\n",
    "    checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=False)\n",
    "    return checkpointer\n",
    "\n",
    "checkpointer = create_model_checkpoint('models', 'vae_seq2seq')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "nb_epoch=100\n",
    "n_steps = int((800000/2)/batch_size)\n",
    "\n",
    "for counter in range(nb_epoch):\n",
    "    print('-------epoch: ',counter,'--------')\n",
    "    vae.fit_generator(sent_generator(TRAIN_DATA_FILE, batch_size/2),\n",
    "                          steps_per_epoch=n_steps, epochs=1, callbacks=[checkpointer],\n",
    "                          validation_data=(data_1_val, data_1_val))\n",
    "    write_log(callback, ['loss', 'val_loss'], [history], counter)\n",
    "    \n",
    "vae.save('models/base_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights('../models/50_e1_d1_ls32_itm96.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project and sample sentences from the latent space\n",
    "Now we build an encoder model that takes a sentence and projects it on the latent space   \n",
    "and a decoder model that goes from the latent space back to the text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project sentences on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# build a generator that can sample sentences from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(repeated_context(decoder_input))\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "_x_decoded_mean = Activation('softmax')(_x_decoded_mean)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on validation sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {v: k for k, v in word_index.items()}\n",
    "sent_encoded = encoder.predict(data_1_val, batch_size = 16)\n",
    "x_test_reconstructed = generator.predict(sent_encoded)\n",
    "max_value = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  3  1 18  7  7  7  7  1  1  8  1  8 35]\n",
      "where can i find the full list of skills for the linkedin skills feature\n",
      "what is the best to to to to the the in the in india\n"
     ]
    }
   ],
   "source": [
    "sent_idx = 672\n",
    "# Apply a function to 1-D slices along the given axis.\n",
    "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx])\n",
    "print(reconstructed_indexes)\n",
    "\n",
    "original_sent = list(np.vectorize(index2word.get)(data_1_val[sent_idx]))\n",
    "o_list = [o for o in original_sent if o]\n",
    "print(' '.join(o_list))\n",
    "\n",
    "word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "w_list = [w for w in word_list if w]\n",
    "print(' '.join(w_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849\n",
      "what is the best to to to to the the in the in india\n",
      "where can i see naked men\n",
      "3217\n",
      "how do i get my quora\n",
      "why do eggs smell like sulfur\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sent_idx1 = random.randint(1, 5000)\n",
    "sent_idx2 = random.randint(1, 5000)\n",
    "# Apply a function to 1-D slices along the given axis.\n",
    "\n",
    "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx1])\n",
    "print(sent_idx1)\n",
    "\n",
    "word_list_1 = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "w_list_1 = [w for w in word_list_1 if w]\n",
    "print(' '.join(w_list))\n",
    "\n",
    "original_sent_1 = list(np.vectorize(index2word.get)(data_1_val[sent_idx1]))\n",
    "o_list_1 = [w for w in original_sent_1 if w]\n",
    "print(' '.join(o_list_1))\n",
    "\n",
    "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx2])\n",
    "print(sent_idx2)\n",
    "\n",
    "word_list_2 = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "w_list_2 = [w for w in word_list_2 if w]\n",
    "print(' '.join(w_list_2))\n",
    "\n",
    "original_sent_2 = list(np.vectorize(index2word.get)(data_1_val[sent_idx2]))\n",
    "o_list_2 = [w for w in original_sent_2 if w]\n",
    "print(' '.join(o_list_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence processing and interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse a sentence\n",
    "def sent_parse(sentence, mat_shape):\n",
    "    sequence = tokenizer.texts_to_sequences(sentence)\n",
    "    padded_sent = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return padded_sent#[padded_sent, sent_one_hot]\n",
    "\n",
    "# input: encoded sentence vector\n",
    "# output: encoded sentence vector in dataset with highest cosine similarity\n",
    "def find_similar_encoding(sent_vect):\n",
    "    all_cosine = []\n",
    "    for sent in sent_encoded:\n",
    "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
    "        all_cosine.append(result)\n",
    "    data_array = np.array(all_cosine)\n",
    "    maximum = data_array.argsort()[-3:][::-1][1]\n",
    "    new_vec = sent_encoded[maximum]\n",
    "    return new_vec\n",
    "\n",
    "# input: two points, integer n\n",
    "# output: n equidistant points on the line between the input points (inclusive)\n",
    "def shortest_homology(point_one, point_two, num):\n",
    "    dist_vec = point_two - point_one\n",
    "    sample = np.linspace(0, 1, num, endpoint = True)\n",
    "    hom_sample = []\n",
    "    for s in sample:\n",
    "        hom_sample.append(point_one + s * dist_vec)\n",
    "    return hom_sample\n",
    "\n",
    "# input: original dimension sentence vector\n",
    "# output: sentence text\n",
    "def print_latent_sentence(sent_vect):\n",
    "    sent_vect = np.reshape(sent_vect,[1,latent_dim])\n",
    "    sent_reconstructed = generator.predict(sent_vect)\n",
    "    sent_reconstructed = np.reshape(sent_reconstructed,[max_len,NB_WORDS])\n",
    "    reconstructed_indexes = np.apply_along_axis(np.argmax, 1, sent_reconstructed)\n",
    "    np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx])\n",
    "    np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx]))\n",
    "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "    w_list = [w for w in word_list if w]\n",
    "    print(' '.join(w_list))\n",
    "    #print(word_list)\n",
    "        \n",
    "def new_sents_interp(sent1, sent2, n):\n",
    "    tok_sent1 = sent_parse(sent1, [15])\n",
    "    tok_sent2 = sent_parse(sent2, [15])\n",
    "    enc_sent1 = encoder.predict(tok_sent1, batch_size = 16)\n",
    "    enc_sent2 = encoder.predict(tok_sent2, batch_size = 16)\n",
    "    test_hom = shortest_homology(enc_sent1, enc_sent2, n)\n",
    "    for point in test_hom:\n",
    "        print_latent_sentence(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Now we can try to parse two sentences and interpolate between them generating new sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the best of of\n",
      "what is the best of of\n",
      "what is the the to to to to the the the the the in india\n",
      "what is the the to to to to the the the the the in india\n",
      "-----------------\n",
      "what is the best of of\n",
      "how do i get a in quora\n",
      "what is the best of to in india\n",
      "what is the best to to a to in in india\n",
      "what i the a to to to the the in the in india\n",
      "what is the the to to to to the the the the the in india\n"
     ]
    }
   ],
   "source": [
    "sentence1 = [texts[sent_idx1]]\n",
    "mysent = sent_parse(sentence1, [15])\n",
    "mysent_encoded = encoder.predict(mysent, batch_size = 16)\n",
    "print_latent_sentence(mysent_encoded)\n",
    "print_latent_sentence(find_similar_encoding(mysent_encoded))\n",
    "\n",
    "sentence2 = [texts[sent_idx2]]\n",
    "mysent2 = sent_parse(sentence2, [15])\n",
    "mysent_encoded2 = encoder.predict(mysent2, batch_size = 16)\n",
    "print_latent_sentence(mysent_encoded2)\n",
    "print_latent_sentence(find_similar_encoding(mysent_encoded2))\n",
    "print('-----------------')\n",
    "\n",
    "new_sents_interp(sentence1, sentence2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
